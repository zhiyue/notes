* mmds
#+TITLE: Mining Massive Datasets on Coursera

** Page Rank
PR的数学(矩阵)形式是Mx = x. 其中M表示链接权值系数矩阵，x则是我们希望求解页面权重矩阵。如果Ax = kx. 那么称x为A的eigenvector(特征向量), 而k则为eigenvalue(特征值).  如果A比较小的话那么可以使用高斯消元法求解，如果比较大的话则比较适合使用迭代方式(Power Iteration)求解：首先分配每个页面相同权重，然后不断迭代直到页面权重改变非常小。

PR也可以看做是random walk(p(t+1) = M*p(t), 一阶马尔科夫), 求解出的x就是stationary distribution. 可以证明，如果graph满足一定条件的话，那么stationary distribution是唯一的并且和t=0时候的分布无关。

那么graph需要满足什么条件呢？有两个问题会导致r不收敛：
- [[http://en.wikipedia.org/wiki/Wikipedia:Dead-end_pages][dead end pages]]. (have no out-links). 最终这些页面的权重会"leak out". dead ends问题可以通过teleport方式解决：我们认为这个页面有可能会跳转到所有可能页面。
- [[http://en.wikipedia.org/wiki/Spider_trap][spider traps]]. (all out-links are within the group). 最终这个群组会吸收所有的权重。spier traps问题也可以通过teleport方式解决：我们分配概率p(0.8~0.9)会跳转到out-links，同时分配1-p会跳转到non-out-links.

更准确地说矩阵M应该是stochastic, irreducible, aperiodic
- stochastic: every column sums to 1. 在dead ends问题中teleport就是添加一些随机跳转链接满足这个条件。
- aperiodic: 某个状态x到状态s, 如果两次之间跳转次数之差，始终是某个k>1的倍数的话，那么就认为这个graph是periodic的。可以通过在自身状态上增加跳转链接来使得graph是aperiodic的。
- irreducible: 不要stuck在某一个状态上。spider traps问题就是可以通过归约SCC(strongly connected component)使得random walker一直在某个状态上。

** Finding Similiar Sets
查找相似集合这个问题，解决办法涉及到三个步骤：1. shingles 2. minhashing 3.locality-sensitive hashing(LSH). 这里我们以查找相似文档为例。

shingles是将文档进行字符切分：k-shingle(k-gram)指将文档内连续k个字符抽取出来组成一个集合。比如k=2, doc=abcab, 那么2-shingles={ab, bc, ca}. 实际应用中k通常选择[5,10]. shingles的特点是，如果doc中某个word发生变化或者是出现段落重新排序的话，那么k-shingles差别是非常小的。为了节省存储和比较时间，我们可以对k-shingles得到的集合中元素进行hash(称为tokens). 这样最终结果我们得到的是set of tokens.

我们可以使用Jaccard Similiarity来衡量两个set相似度指标：Sim(C1, C2) = Intersection(C1, C2) / Union(C1, C2). 如果我们用矩阵形式表示的话，row可以表示所有tokens, 而column则表示所有docs, M(i,j)则表示doc#j是否含有ith的token. M是一个布尔矩阵并且非常稀疏。如果要求解Sim(C1, C2)只需要抽取对应columns即可。

然后我们引入minhashing. minhashing主要作用是特别稀疏vector通过hash函数转换成为稠密vector. 假设rows是随机排列的话，minhash function h(C)是这个column上有多少个1出现在row的第一个排列中(the number of the first(in the permuted order) row in which column C has 1). 我们可以使用h(C1)和h(C2)相似度来作为Sim(C1,C2). 可是rows的所有排列组合可能是(# of rows)!, 所以实际中通常我们选择k(k~=100)左右个随机排列组合，这样得到的minhash function h(C)实际上是100*1向量。下图给了一个求解minhash的例子. 我们看signature matrix第二行第三列为什么是4，这是因为第二个permutation中只有4th对应的row在第三列才出现第一个1.

file:./images/mmds-minhashing-example.png

剩下的问题就是我们如何使用hash-function来模拟随机排列组合，下面是具体实现办法。其实我们更加关心的是两个r在同一个hash-function上的顺序。

file:./images/mmds-minhashing-impl.png

最后我们相当于需要为这些vector建立"索引". 这个方法称为 [[file:./images/mmds_locality_sensitive_hashing.pdf][LSH(局部敏感哈希)]]. 顾名思义就是将vector拆分称为多个小部分，针对每个部分进行hash. 如果一个C在某个小部分hash相同的话，那么这个C就可以作为候选(candidates). 最终我们会对这个C全量vector计算相似度。具体地来说，这些小部分称为band(b = # of band), 每个band里面有r个rows. 还有参数k来控制hash的bucket. 假设我们希望能够找出相似度为s的文档的话：
- 那么C1,C2在一个band上完全相同的概率是 s^b.
- 而C1,C2在所有band上都不相同的概率则是 (1-s^b) ^ r.
- C1,C2在任意一个band上相同概率是 1 - (1-s^b) ^ r.
我们希望的函数形状是：y=1.0 if sim >= s, 0.0 if sim < s. 这是一个阶梯函数。而实际上1-(1-s^b)^r这个函数是一个S形状函数。通过控制b, r参数可以控制函数形状来调整false-pos和false-neg概率。

